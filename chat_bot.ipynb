{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kELJ-_fWphf3"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos = {\n",
        "    \"Entrada\": [\n",
        "        \"Hola\",\n",
        "        \"Hola, ¿cómo estás?\",\n",
        "        \"Buenas tardes\",\n",
        "        \"Buenas noches\",\n",
        "        \"¿Qué tal?\",\n",
        "        \"¿Cómo va todo?\",\n",
        "        \"¿Cómo te va?\",\n",
        "        \"¡Hola a todos!\",\n",
        "        \"¡Hola, amigo!\",\n",
        "        \"¡Hola, equipo!\",\n",
        "        \"¿Qué hay de nuevo?\",\n",
        "        \"¿Qué hay?\",\n",
        "        \"¡Buenos días!\",\n",
        "        \"Saludos\",\n",
        "        \"¿Qué pasa?\",\n",
        "        \"Hola, ¿qué haces?\",\n",
        "        \"Hola, ¿cómo te va?\",\n",
        "        \"¡Hola! ¿Cómo está tu día?\",\n",
        "        \"¡Hola! ¿Qué planes tienes hoy?\",\n",
        "        \"Hola, ¿cómo has estado?\",\n",
        "        \"¡Hola, long time no see!\",\n",
        "        \"¿Cómo te sientes hoy?\",\n",
        "        \"¿Cómo está tu familia?\",\n",
        "        \"¡Qué alegría verte!\",\n",
        "        \"¡Hola! ¿Todo bien?\",\n",
        "        \"¡Hola! ¿Cómo te ha ido?\",\n",
        "        \"¡Saludos! ¿Cómo están todos?\",\n",
        "        \"¿Cómo está la vida?\",\n",
        "        \"Hola, ¿qué cuentas?\",\n",
        "        \"Hola, ¿qué tal tu semana?\",\n",
        "        \"Hola, ¿cómo te ha ido últimamente?\",\n",
        "        \"¡Hola! ¿Cómo va la vida?\",\n",
        "        \"Hola, ¿cómo han estado las cosas?\",\n",
        "        \"¡Hola! ¿Cómo está todo por allá?\",\n",
        "        \"¡Hola! ¿Cómo te ha tratado la semana?\",\n",
        "        \"Hola, ¿cómo van las cosas?\",\n",
        "        \"Hola, ¿qué tal el trabajo?\",\n",
        "        \"¿Cómo está tu día hoy?\",\n",
        "        \"¡Hola! ¿Qué hay de interesante?\",\n",
        "        \"¡Hola! ¿Qué estás haciendo?\",\n",
        "        \"¡Hasta luego!\",\n",
        "        \"Adiós\",\n",
        "        \"Nos vemos\",\n",
        "        \"Hasta la próxima\",\n",
        "        \"Hasta pronto\",\n",
        "        \"Que tengas un buen día\",\n",
        "        \"Cuídate\",\n",
        "        \"Adiós, que estés bien\",\n",
        "        \"Hasta más tarde\",\n",
        "        \"Que te vaya bien\",\n",
        "        \"Nos vemos luego\",\n",
        "        \"Chao\",\n",
        "        \"Adiós, que tengas un buen día\",\n",
        "        \"Hasta la vista\",\n",
        "        \"Que tengas un excelente día\",\n",
        "        \"Adiós, cuídate mucho\",\n",
        "        \"Hasta la próxima, cuídate\",\n",
        "        \"Hasta luego, nos vemos pronto\",\n",
        "        \"Que te vaya genial\",\n",
        "        \"Cuídate y hasta luego\",\n",
        "        \"Hasta luego, cuídate\",\n",
        "        \"Adiós, espero verte pronto\",\n",
        "        \"Hasta pronto, cuídate\",\n",
        "        \"Chao, cuídate mucho\",\n",
        "        \"Adiós, que todo te salga bien\",\n",
        "        \"Nos vemos pronto, cuídate\",\n",
        "        \"Hasta luego, disfruta tu día\",\n",
        "        \"Hasta la próxima, que estés bien\",\n",
        "        \"Adiós, que tengas un buen fin de semana\",\n",
        "        \"Hasta pronto, que todo te salga bien\"\n",
        "    ],\n",
        "    \"Respuesta\": [\n",
        "        \"¡Holi!\",\n",
        "        \"Estoy bien, gracias. ¿Y tú?\",\n",
        "        \"Buenas tardes, ¿en qué puedo ayudarte?\",\n",
        "        \"Buenas noches, ¿cómo estuvo tu día?\",\n",
        "        \"Todo bien, ¿y tú?\",\n",
        "        \"Todo en orden, gracias.\",\n",
        "        \"Me va bien, gracias.\",\n",
        "        \"¡Hola a todos! ¿Cómo están?\",\n",
        "        \"¡Hola, amigo! ¿Qué hay de nuevo?\",\n",
        "        \"¡Hola, equipo! ¡Listos para trabajar!\",\n",
        "        \"Nada nuevo, ¿y tú?\",\n",
        "        \"Todo tranquilo.\",\n",
        "        \"¡Buenos días! ¿Cómo amaneciste?\",\n",
        "        \"¡Saludos! ¿Cómo te encuentras?\",\n",
        "        \"Todo bien, ¿y tú?\",\n",
        "        \"Estoy trabajando en un proyecto, ¿y tú?\",\n",
        "        \"Me va bien, gracias. ¿Qué hay de nuevo?\",\n",
        "        \"Hoy ha sido un buen día, gracias.\",\n",
        "        \"Nada planeado, solo relajándome.\",\n",
        "        \"Todo bien, solo disfrutando el día.\",\n",
        "        \"¡Hola! Ha pasado tiempo, ¿verdad?\",\n",
        "        \"Hoy me siento bien, gracias por preguntar.\",\n",
        "        \"Mi familia está bien, gracias.\",\n",
        "        \"Igualmente, me alegra verte también.\",\n",
        "        \"Todo bien, gracias.\",\n",
        "        \"He estado bien, gracias.\",\n",
        "        \"Todo bien, solo disfrutando el día.\",\n",
        "        \"Las cosas van bien, gracias por preguntar.\",\n",
        "        \"Todo en calma, ¿y tú?\",\n",
        "        \"La semana ha sido buena, gracias.\",\n",
        "        \"He estado ocupado, pero bien.\",\n",
        "        \"Todo tranquilo, ¿y tú?\",\n",
        "        \"Las cosas van bien, ¿y las tuyas?\",\n",
        "        \"El trabajo va bien, gracias por preguntar.\",\n",
        "        \"Hoy estoy teniendo un buen día.\",\n",
        "        \"Nada de especial, ¿y tú?\",\n",
        "        \"Estoy trabajando en algunas cosas, ¿y tú?\",\n",
        "        \"¡Hasta luego! Que tengas un buen día.\",\n",
        "        \"Adiós, que estés bien.\",\n",
        "        \"Nos vemos, cuídate.\",\n",
        "        \"Hasta la próxima, cuídate mucho.\",\n",
        "        \"Hasta pronto, que tengas un buen día.\",\n",
        "        \"Cuídate, ¡nos vemos!\",\n",
        "        \"Adiós, que todo te salga bien.\",\n",
        "        \"Hasta más tarde, cuídate.\",\n",
        "        \"Que te vaya bien, ¡nos vemos pronto!\",\n",
        "        \"Nos vemos luego, cuídate.\",\n",
        "        \"Chao, que estés bien.\",\n",
        "        \"Adiós, que tengas un buen día.\",\n",
        "        \"Nos vemos pronto, cuídate mucho.\",\n",
        "        \"Hasta luego, disfruta tu día.\",\n",
        "        \"Hasta la próxima, que estés bien.\",\n",
        "        \"Que tengas un buen fin de semana.\",\n",
        "        \"Hasta pronto, que todo te salga bien.\"\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "q2Oxf5KAqFyU"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. **Preparación de los datos**\n",
        "# Asegurarse de que las listas de entrada y respuesta tengan la misma longitud\n",
        "entradas = datos[\"Entrada\"][:54]  # Seleccionar las primeras 54 entradas\n",
        "respuestas = datos[\"Respuesta\"][:54]  # Seleccionar las primeras 54 respuestas\n",
        "\n",
        "# Dividir los datos (asegúrate de que ambas listas se dividan al mismo tiempo)\n",
        "entradas_train, entradas_test, respuestas_train, respuestas_test = train_test_split(\n",
        "    entradas, respuestas, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 2. **Tokenización**\n",
        "# Crear y ajustar el tokenizador\n",
        "tokenizador = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizador.fit_on_texts(entradas_train + respuestas_train)  # Ajustar el tokenizador a los datos de entrada y respuesta\n",
        "\n",
        "# Convertir texto en secuencias\n",
        "secuencias_entrada_train = tokenizador.texts_to_sequences(entradas_train)\n",
        "secuencias_entrada_test = tokenizador.texts_to_sequences(entradas_test)\n",
        "secuencias_respuesta_train = tokenizador.texts_to_sequences(respuestas_train)\n",
        "secuencias_respuesta_test = tokenizador.texts_to_sequences(respuestas_test)\n",
        "\n",
        "# 3. **Rellenar secuencias**\n",
        "# Calcular la longitud máxima de las secuencias\n",
        "medida_maxima = max(max(len(seq) for seq in secuencias_entrada_train),\n",
        "                    max(len(seq) for seq in secuencias_respuesta_train))\n",
        "\n",
        "# Rellenar secuencias para que tengan la misma longitud (para el conjunto de entrenamiento)\n",
        "x_entrenamiento = tf.keras.preprocessing.sequence.pad_sequences(secuencias_entrada_train, maxlen=medida_maxima, padding='post')\n",
        "y_entrenamiento = tf.keras.preprocessing.sequence.pad_sequences(secuencias_respuesta_train, maxlen=medida_maxima, padding='post')\n",
        "\n",
        "# Rellenar secuencias para las pruebas\n",
        "x_pruebas = tf.keras.preprocessing.sequence.pad_sequences(secuencias_entrada_test, maxlen=medida_maxima, padding='post')\n",
        "y_pruebas = tf.keras.preprocessing.sequence.pad_sequences(secuencias_respuesta_test, maxlen=medida_maxima, padding='post')\n",
        "\n",
        "# Imprimir dimensiones de las secuencias\n",
        "print(f'X_train shape: {x_entrenamiento.shape}, y_train shape: {y_entrenamiento.shape}')\n",
        "print(f'X_test shape: {x_pruebas.shape}, y_test shape: {y_pruebas.shape}')\n",
        "\n",
        "# 4. **Definición del modelo**\n",
        "# Datos para el modelo\n",
        "vocab_size = len(tokenizador.word_index) + 1  # Tamaño del vocabulario\n",
        "embedding_dim = 64  # Dimensión del embedding\n",
        "hidden_units = 128  # Unidades ocultas en LSTM\n",
        "\n",
        "# Definir el modelo\n",
        "modelo = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim),  # Capa de embedding\n",
        "    tf.keras.layers.LSTM(hidden_units, return_sequences=True),  # Capa LSTM\n",
        "    tf.keras.layers.Dense(vocab_size, activation='softmax')  # Capa de salida con activación softmax\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "modelo.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 5. **Entrenamiento del modelo**\n",
        "modelo.fit(x_entrenamiento, np.expand_dims(y_entrenamiento, -1), epochs=150, batch_size=124, validation_split=0.2)\n",
        "\n",
        "# 6. **Función para generar respuestas**\n",
        "def generar_respuesta(contexto):\n",
        "    # Limpiar y preparar el contexto\n",
        "    contexto_limpio = contexto.lower().strip()  # Convertir a minúsculas y eliminar espacios\n",
        "    secuencia = tokenizador.texts_to_sequences([contexto_limpio])  # Convertir el contexto en secuencia\n",
        "    secuencia_pad = tf.keras.preprocessing.sequence.pad_sequences(secuencia, maxlen=medida_maxima, padding='post')  # Rellenar la secuencia\n",
        "\n",
        "    # Predecir la respuesta\n",
        "    prediccion = modelo.predict(secuencia_pad)  # Hacer la predicción\n",
        "    respuesta_idx = np.argmax(prediccion[0], axis=-1)  # Obtener el índice de la palabra más probable\n",
        "\n",
        "    # Convertir el índice de vuelta a texto\n",
        "    respuesta_palabras = [tokenizador.index_word[i] for i in respuesta_idx if i > 0]  # Ignorar el índice 0\n",
        "    return ' '.join(respuesta_palabras)  # Devolver la respuesta como texto\n",
        "\n",
        "# 7. **Probar la función de generación**\n",
        "contexto_prueba = \"Hola\"  # Definir un contexto de prueba\n",
        "print(generar_respuesta(contexto_prueba))  # Imprimir la respuesta generada\n"
      ],
      "metadata": {
        "id": "gIJ_xeWAs-ae"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}